{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhYx0Qn0/dixltVUHY2qfa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VamsiReddy-hub/LMS_ASSIGNMENTS/blob/main/GeminiAPI_Image_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t56S6dbL_eZV"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('Gemin_key')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "s5dwLFKR_pjk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "img = PIL.Image.open('/content/WhatsApp Image 2025-03-11 at 12.23.15_2d5164dd.jpg')\n",
        "img\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"Write a short, engaging blog post based on this picture.  It should include a description of the meal in the photo and talk about my journey meal prepping.\", img],\n",
        "stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "nCoYscV2_38j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "q6XPlhSjAYo0",
        "outputId": "47f33369-3ab2-4d02-ed43-077e3774347e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ## My Meal Prep Journey: From Chaos to Delicious!\n> \n> Look at this vibrant spread!  These aren't just leftovers; these are my meticulously crafted, perfectly portioned lunch containers.  Each one is filled with fluffy white rice, tender teriyaki chicken, vibrant orange and red bell peppers, and a healthy helping of broccoli.  It’s a delicious and balanced meal, ready to go whenever I am.\n> \n> My journey to mastering meal prep hasn't been a straight path. I used to be a \"wing it\" kind of person, resulting in a chaotic mix of unhealthy takeout and rushed, unbalanced meals.  I was always tired and never satisfied.  \n> \n> Then, I realized the power of planning.  Starting with small, achievable goals – like prepping one lunch a week – made a huge difference. I slowly increased my preparation to multiple meals and now, I'm prepping for the entire work week!\n> \n> The benefit is not just the convenience, but also the significant improvement in my health and overall well-being.  This is a testament to how much better I feel with mindful eating.  The preparation might seem daunting at first, but the results are incredibly rewarding: more energy, healthier choices, and less time spent figuring out what to eat.\n> \n> So, if you're considering joining the meal prep bandwagon, just start small.  One step at a time, and you'll be amazed at the transformation!  And honestly, looking at these gorgeous containers makes the whole process worth it.  What are your favorite meal prep tips? Let me know in the comments!\n"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "# Open an image\n",
        "image_path = \"/content/WhatsApp Image 2025-03-11 at 12.50.22_a6751b72.jpg\"\n",
        "image = Image.open(image_path)\n",
        "# Generate a description of the image\n",
        "response = model.generate_content([\"Describe image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "a5itlvwlAwuE",
        "outputId": "891f5524-8462-4e50-f684-bfd29c802695"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "Close-up view of a woman with shoulder-length, curly brown hair. \n",
            "\n",
            "\n",
            "She is light-skinned and has a warm, friendly expression. She is smiling and pointing to her right with her index finger. \n",
            "\n",
            "\n",
            "She is wearing a teal-colored, three-quarter sleeve top or kurta with a subtle gold print pattern. The pattern seems to be small, repeating floral or paisley designs. The neckline is a modest, rounded collar.\n",
            "\n",
            "\n",
            "The background is a plain, bright white, which makes the woman and her clothing stand out clearly. The lighting is soft and even, without harsh shadows.  Her arms are crossed, with one arm bent at the elbow and the other across her body. She looks directly at the camera.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/logo1.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Identify the brand or company associated with this logo.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "L3ovgSDaFfIM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "42853720-e6f0-4888-c32c-e2b3915cdf93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's the logo for **Amazon**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"product.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"What product is shown in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "BVlbNwwftSb4",
        "outputId": "93a6b57d-9d4e-4131-ee7c-b5f33d7c5633"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's a pair of black over-ear headphones.  They appear to be noise-canceling headphones, but that can't be confirmed from the image alone.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Simage_path = \"invoice.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Extract the price from this image.\", image])\n",
        "print(response.text)ugest similar product to this one.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "I_N1_dlPtSo3",
        "outputId": "ced62bd1-f60b-4040-fccb-ac6144c7234c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some suggestions for similar products to the pictured black over-ear headphones.  To give you the best recommendations, I need more information.  However, based solely on the image, here are some general categories and examples:\n",
            "\n",
            "**Similar Styles & Features (General):**\n",
            "\n",
            "* **Other Over-Ear Headphones:**  Look for other brands that offer similar designs – closed-back, circumaural (covering the entire ear) headphones.  Brands like Sony, Bose, Sennheiser, Audio-Technica, and JBL offer a wide variety of over-ear headphones in various price ranges.\n",
            "* **Noise-Cancelling Headphones:** If you're looking for noise cancellation,  many of the brands mentioned above (especially Sony and Bose) have popular noise-cancelling over-ear headphones.\n",
            "\n",
            "\n",
            "**To give better recommendations, please tell me:**\n",
            "\n",
            "* **Your Budget:** Are you looking for budget-friendly, mid-range, or high-end headphones?\n",
            "* **Primary Use:** What will you primarily use these headphones for? (Music, gaming, calls, etc.)\n",
            "* **Desired Features:** Are you looking for noise cancellation, Bluetooth connectivity, a microphone, a specific sound signature (bass-heavy, balanced, etc.)?\n",
            "* **Comfort Level:** How important is comfort for extended listening sessions?\n",
            "\n",
            "\n",
            "Once you provide more details, I can offer more specific and helpful suggestions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"invoice.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Extract the price from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "wgiytAHkud-j",
        "outputId": "059fa56a-8364-4ae0-807e-d5ba7619aeff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of each item is $10.00.  The sub-total is $100.00, the tax is 10%, and the grand total is $100.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Extract the price, currency, and any discounts trom this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "I-HWPdfDwuuU",
        "outputId": "825b2b09-4931-4efd-8d11-d93f099bc690"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the extracted information from the provided invoice image:\n",
            "\n",
            "* **Price:** $10.00 (per item)\n",
            "* **Currency:** USD ($)\n",
            "* **Discounts:** None explicitly stated.  While the Grand Total is the same as the Sub Total,  a 10% tax is shown, implying the $100.00 grand total includes the tax.  There's no discount applied before tax.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"bicycle.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Identify all objects present in this image\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "RLJVHRJrwvgD",
        "outputId": "ae37549e-7f25-4427-ae4e-39a080cbebf8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the objects present in the image:\n",
            "\n",
            "* **Two men:**  Riding bicycles. One is wearing a blue shirt and camouflage shorts, the other a gray long-sleeved shirt and jeans, and a red cap.\n",
            "* **Two bicycles:** One appears to be yellow and black, the other white.  Both are standard city bikes.\n",
            "* **A motorcycle:** Parked on the left side of the image.\n",
            "* **A building:** A building with a roller door, windows and a small porch-like area visible in the background.\n",
            "* **A man (in the background):** Sitting inside the building, possibly observing the cyclists.\n",
            "* **Chairs:** Two chairs are visible inside the building, behind the men.\n",
            "* **Street:**  A wet street where the bicycles are riding.\n",
            "* **Vegetation:** Some grass can be seen along the edge of the street.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWSH_CUOzUcr",
        "outputId": "2656902d-321e-4814-e89b-309d56e76990"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.0.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube, youtube-transcript-api\n",
            "Successfully installed pytube-15.0.0 youtube-transcript-api-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "def get_youtube_transcript(video_url):\n",
        "    \"\"\"Fetches the transcript of a YouTube video.\"\"\"\n",
        "    video_id = video_url.split(\"v=\")[1].split(\"&\")[0]\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    full_text = \" \".join([t[\"text\"] for t in transcript])\n",
        "    return full_text\n",
        "\n",
        "video_url = \"https://www.youtube.com/watch?v=unYDoA8QGH0&list=PLWEpztHwA4ZT2QlHC74oIz4MsawcvE-QX\"\n",
        "video_transcript = get_youtube_transcript(video_url)\n",
        "print(\"Transcript:\\n\", video_transcript[:500])  # Show first 500 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyIeUC77zU_w",
        "outputId": "dded3543-0f50-45c4-a7c9-084f7810844b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:\n",
            " hi guys today I'm going to introduce you what is machine learning uh these are my presentation content what is machine learning what are the different applications of machine learning different types of machine learning and how to build a machine learning system or model then various kinds of algorithms and later on in this series we are going to take a Hands-On you know case studies or doing programming for various kinds of up algorithms so what is machine learning so machine learning is nothin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(text):\n",
        "    \"\"\"Summarizes the YouTube video transcript using Gemini AI.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    prompt = f\"Summarize the following YouTube video transcript:\\n\\n{text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "summary = summarize_video(video_transcript)\n",
        "print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "UjphE0yCzYUe",
        "outputId": "b10a8f0d-4d79-4ef0-c1d8-fe7d92c0e2c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " This YouTube video introduces machine learning, covering its definition, applications, types, and the process of building a machine learning model.  Machine learning is defined as learning from data, a subfield of AI enabling smarter applications.  The video highlights applications in speech recognition, web search, recommendation systems, computer vision, information retrieval, and fraud detection.  Three main types of machine learning are explained: supervised (learning from labeled data, including classification and regression), unsupervised (learning from unlabeled data, including clustering and dimensionality reduction), and reinforcement learning (learning through trial and error and rewards/penalties).  The video details the process of building a model, including data preprocessing (cleaning, scaling, encoding, feature selection), algorithm selection (e.g., decision trees, random forests), model building, and evaluation.  The presenter promises future videos with hands-on case studies and algorithm implementations using datasets like the Iris dataset.  Key terminology such as features, attributes, samples, target variables, and the workflow of a machine learning pipeline are also explained.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_insights(text):\n",
        "    \"\"\"Extracts key insights from the YouTube video transcript.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    prompt = f\"Extract the key takeaways and insights from this YouTube video:\\n\\n{text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "insights = extract_video_insights(video_transcript)\n",
        "print(\"Key Insights:\\n\", insights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "0JT7aDNz2ZqD",
        "outputId": "c1f1a8b4-9392-4500-990a-6a8323217ce0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Insights:\n",
            " This YouTube video provides an introduction to machine learning. Here are the key takeaways and insights:\n",
            "\n",
            "**What is Machine Learning?**\n",
            "\n",
            "* **Definition:** Machine learning is essentially learning from data.  It's a subfield of artificial intelligence that allows computers to learn from data without explicit programming.  The process involves using past data (training data) to build a model that can predict future outcomes.\n",
            "* **Key Concepts:**  Training data (experience), model building, prediction, algorithm selection.  The process involves feeding data into an algorithm, which generates a model used for prediction.\n",
            "\n",
            "**Applications of Machine Learning:**\n",
            "\n",
            "The video highlights a broad range of applications, showcasing machine learning's versatility:\n",
            "\n",
            "* **Speech Recognition:**  Powering virtual assistants like Siri and Google Assistant.\n",
            "* **Web Search:**  Improving search engine results (using algorithms like Naive Bayes).\n",
            "* **Recommendation Systems:**  Suggesting products or content based on user preferences.\n",
            "* **Computer Vision:**  Analyzing images and videos to identify objects and understand content.\n",
            "* **Information Retrieval:**  Processing vast amounts of data to deliver relevant information (like Google search).\n",
            "* **Fraud Detection:**  Identifying malicious activities online.\n",
            "\n",
            "**Types of Machine Learning:**\n",
            "\n",
            "The video categorizes machine learning into three main types:\n",
            "\n",
            "* **Supervised Learning:** The training data includes labeled outcomes (the \"correct answer\").  The model learns to map inputs to these known outputs.  This is further divided into:\n",
            "    * **Classification:** Predicting categorical outcomes (e.g., spam/not spam, types of flowers).\n",
            "    * **Regression:** Predicting continuous outcomes (e.g., salary, temperature).\n",
            "* **Unsupervised Learning:** The training data lacks labeled outcomes.  The model aims to discover patterns and structures within the data. Examples include:\n",
            "    * **Clustering:** Grouping similar data points together.\n",
            "    * **Dimensionality Reduction:** Reducing the number of variables while preserving important information.\n",
            "* **Reinforcement Learning:** An agent learns to interact with an environment by trial and error, receiving rewards or penalties for its actions.  This is often used in game playing and robotics.\n",
            "\n",
            "**Building a Machine Learning Model: The Process**\n",
            "\n",
            "The video outlines a typical workflow:\n",
            "\n",
            "1. **Data Preprocessing:** Cleaning and preparing the data (handling missing values, scaling features, encoding categorical variables, feature selection/dimensionality reduction).\n",
            "2. **Algorithm Selection:** Choosing an appropriate algorithm based on the type of problem (classification, regression, etc.) and the characteristics of the data.\n",
            "3. **Model Training:** Applying the chosen algorithm to the training data to build a predictive model.\n",
            "4. **Model Evaluation:** Assessing the model's performance using metrics like accuracy.  The speaker emphasizes building multiple models and comparing their performance.\n",
            "\n",
            "**Key Terms:**\n",
            "\n",
            "The video defines important terms like features, attributes, samples, instances, observations, target variable, and response variable.  It also highlights the importance of understanding the Iris dataset as a common benchmark.\n",
            "\n",
            "\n",
            "In summary, the video provides a comprehensive yet introductory overview of machine learning, covering its core concepts, applications, types, and the process of building models.  It emphasizes the practical aspects and the need for experimentation with different algorithms.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dnILCw7d2cly"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}